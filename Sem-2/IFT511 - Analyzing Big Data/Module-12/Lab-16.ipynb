{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: Harsh Siddhapura\n",
    "# ASU ID: 1230169813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 16: Naive Bayes Classifier \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Write a script that fits a Gaussian Naive Bayes classifier to the given dataset. The script should:\n",
    "- Read the dataset using proper function for reading a libsvm file.\n",
    "- Convert the feature data into a dense array using X.todense().\n",
    "- Split the data into train/test parts. Use 30% of the data for testing.\n",
    "- Create a machine learning pipeline that includes a standard scalar and a Gaussian Naive Bayes Classifier.\n",
    "- Fit the pipeline to the training data. Since there are not different parameters to try out, and due to the limitations of the cross_valiation_score implementation, we will not use k-fold cross validation for this classifier.\n",
    "- Use the pipe.score() function to fit the pipe scalar to the test set, and find the accuracy.\n",
    "- Run your code, make sure it does not contain any errors. What is the classification accuracy returned by the pipe's score function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5150987818609889\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (replace 'your_dataset.libsvm' with the actual file path)\n",
    "X, y = load_svmlight_file('a9a.txt')\n",
    "\n",
    "# Convert feature data to dense array\n",
    "X_dense = np.array(X.todense())\n",
    "\n",
    "# Split data into train/test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Create a pipeline with standard scaler and Gaussian Naive Bayes classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('nb', GaussianNB())          # Gaussian Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Modify your script by adding a part that fits a DT classifier to the data:\n",
    "- Create another pipeline that includes a standard scalar and a Decision Tree Classifier.\n",
    "- Use a parameter grid that evaluates two impurity calculation metrics: entropy & gini, and a maximum tree depth of 10, 50 & 100.\n",
    "- Fit this pipeline to the training data using k-fold cross validation with k=5. \n",
    "- Find the best performing model and the corresponding parameter values.\n",
    "- Create another pipeline that contains the same standard scalar and the best performing model.\n",
    "- Use this pipeline to call the score() function over the test data.\n",
    "- Run your code, make sure it does not contain any errors. What is the classification accuracy obtained on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test Accuracy: 0.8324291124987204\n",
      "Best Hyperparameters: {'dt__criterion': 'gini', 'dt__max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (replace 'your_dataset.libsvm' with the actual file path)\n",
    "X, y = load_svmlight_file('a9a.txt')\n",
    "\n",
    "# Convert feature data to dense array\n",
    "X_dense = np.array(X.todense())\n",
    "\n",
    "# Split data into train/test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Create a pipeline with standard scaler and Decision Tree Classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('dt', DecisionTreeClassifier())  # Decision Tree Classifier\n",
    "])\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [10, 50, 100]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Best Model Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Modify your script by adding a part that fits an SVM classifier to the data:\n",
    "- Create another pipeline that includes a standard scalar and an SVM classifier.\n",
    "- Use a parameter grid that evaluates three kernels: linear, polynomial (with d values = 2 & 3), rbf (with gamma values = 0.001, 0.1, 2).\n",
    "- Fit this pipeline to the training data using k-fold cross validation with k=5. \n",
    "- Find the best performing model and the corresponding parameter values.\n",
    "- Create another pipeline that contains the same standard scalar and the best performing model.\n",
    "- Use this pipeline to call the score() function over the test data.\n",
    "- Run your code, make sure it does not contain any errors. What is the obtained classification accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test Accuracy: 0.8446666666666667\n",
      "Best Hyperparameters: {'svm__degree': 2, 'svm__gamma': 0.001, 'svm__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (replace 'your_dataset.libsvm' with the actual file path)\n",
    "X, y = load_svmlight_file('a9a.txt')\n",
    "\n",
    "# Convert feature data to dense array\n",
    "X_dense = np.array(X.todense())\n",
    "\n",
    "# Split data into train/test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Create a pipeline with standard scaler and SVM classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('svm', SVC())  # SVM classifier\n",
    "])\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'svm__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svm__degree': [2, 3],\n",
    "    'svm__gamma': [0.001, 0.1, 2]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Best Model Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which classifier (and parameter values) gave the highest accuracy?\n",
    "\n",
    "Test accuracies for all 3 classifiers are as follows:  \n",
    "\n",
    "1. Gaussian = 0.5150987818609889\n",
    "2. Decision Tree = 0.8324291124987204\n",
    "3. SVM Classifier = 0.8446666666666667\n",
    "\n",
    "According to the parameter value {'svm__degree': 2, 'svm__gamma': 0.001, 'svm__kernel': 'linear'}, the SVM classifier is most accurate with accuracy of 0.8446666666666667."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
